{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11cd0cb-8d15-4c57-b45e-b35d3c778789",
   "metadata": {},
   "source": [
    "<H6 align=\"center\">Белорусский государственный университет </H6>\n",
    "<H6 align=\"center\">Механико-математический факультет </H6>\n",
    "<H6 align=\"center\">Кафедра дифференциальных уравнений  и системного анализа </H6>\n",
    "\n",
    "<H2 align=\"center\">КУРСОВАЯ РАБОТА</H2>\n",
    "\n",
    "\n",
    "<H2 align=\"center\">Распознавание жестов</H2>\n",
    "\n",
    "<H4 align=\"center\">Габбасов Илья </H4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f3a11-56f8-4976-bae5-e20f8b667e33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Создание набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc5b338-6de7-4fe8-b9ba-884dc1b8c877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a2ee64-a1e5-473b-9ad0-868f31b0680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем путь к директории, где будут храниться данные\n",
    "DATA = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69784616-0dc7-41b0-966a-d4541582695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем существование директории и создаем ее, если она не существует\n",
    "if not os.path.exists(DATA):\n",
    "    os.makedirs(DATA)\n",
    "\n",
    "# задаем количество жестов, которые будут распознаваться\n",
    "num_of_gestures = 32\n",
    "\n",
    "# задаем количество изображений, которые будут собраны для каждого жеста\n",
    "dataset_size = 200\n",
    "\n",
    "# создаем объект VideoCapture для получения видеопотока\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# проходим по всем жестам и создаем для каждого жеста отдельную папку\n",
    "for i in range(num_of_gestures):\n",
    "    if not os.path.exists(os.path.join(DATA, str(i))):\n",
    "        os.makedirs(os.path.join(DATA, str(i)))\n",
    "        \n",
    "# выводим сообщение о том, какой жест собираем в данный момент\n",
    "    print('%%% Сбор данных для жеста под номером {} %%%'.format(i))\n",
    "    \n",
    "# ждем, пока пользователь не нажмет кнопку 'q', чтобы начать сбор данных для данного жеста\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.putText(frame, ' Готовы? Для создания нажмите Q ! ', (10, 50), cv2.FONT_HERSHEY_COMPLEX, 0.9, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "            \n",
    "# начинаем сбор данных для данного жеста            \n",
    "    counter = 0\n",
    "    \n",
    "    while counter < dataset_size:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        \n",
    "# сохраняем изображение с именем '{номер_жеста}_{номер_изображения}.jpg'\n",
    "        cv2.imwrite(os.path.join(DATA, str(i), '{}.jpg'.format(counter)), frame)\n",
    "        counter += 1\n",
    "        \n",
    "# освобождаем поток объекта VideoCapture и закрываем все окна        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd56ba-1830-4bde-851f-6e6c764e8449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Отслеживание кистей рук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "845fb6d0-ba8e-4fc3-9166-bca82c9b1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# используем модель для обнаружения и отслеживания рук\n",
    "mp_hands=mp.solutions.hands\n",
    "\n",
    "# используем модуль, содержащий стили для рисования\n",
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_drawing_styles=mp.solutions.drawing_styles\n",
    "\n",
    "# cоздаем объект-экземпляр модели для обнаружения и отслеживания рук\n",
    "# на cтатическом изображении.\n",
    "hands=mp_hands.Hands(static_image_mode=True,min_detection_confidence=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5289b87-884f-4bea-a5f5-0cdb21a11bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем список папок в директории\n",
    "folders = os.listdir(DATA)\n",
    "\n",
    "# создаем сетку графиков размером 7x5\n",
    "fig, axs = plt.subplots(7, 5, figsize=(10, 10))\n",
    "\n",
    "# проходим по каждой папке и выводим по одному изображению в каждой строке\n",
    "for i, folder in enumerate(folders):\n",
    "    \n",
    "    # получаем список файлов в папке\n",
    "    files = os.listdir(os.path.join(DATA, folder))\n",
    "    if len(files) == 0:\n",
    "        continue\n",
    "        \n",
    "    # выбираем первый файл\n",
    "    img_path = os.path.join(DATA, folder, files[0])\n",
    "    \n",
    "    # загружаем изображение и конвертируем в RGB\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # обрабатываем изображение и рисуем на нем ориентиры рук\n",
    "    results = hands.process(img_rgb)\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            img_rgb,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "        \n",
    "    # выводим изображение в сетке графиков\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    axs[row][col].imshow(img_rgb)\n",
    "    axs[row][col].set_title(folder)\n",
    "    axs[row][col].axis('off')\n",
    "\n",
    "# удаляем лишние ячейки сетки, если они есть\n",
    "for i in range(len(folders), 35):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    fig.delaxes(axs[row][col])\n",
    "\n",
    "# показываем график\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb99173-4413-4117-b4e8-102f0e8c8758",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Создание обучающего набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5c049-8761-4ad3-a207-5ee54d8eff0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# создаем списки для хранения извлеченных данных о руках и метках\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "# проходим по каждой папке и файлу в текущей директории\n",
    "for dir_ in os.listdir(DATA):\n",
    "    for img_path in os.listdir(os.path.join(DATA,dir_)):\n",
    "        data_aux=[]\n",
    "        img=cv2.imread(os.path.join(DATA,dir_,img_path))\n",
    "        img_rgb=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        results=hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            # если обнаружены ориентиры рук на изображении\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # перебираем каждый ориентир руки на изображении\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    # вычисляем координаты ориентира\n",
    "                    x=hand_landmarks.landmark[i].x\n",
    "                    y=hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x)\n",
    "                    data_aux.append(y)\n",
    "                    \n",
    "            # добавляем данные о руке       \n",
    "            data.append(data_aux)\n",
    "            \n",
    "            # добавляем метку для текущего изображения\n",
    "            labels.append(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec1b0fb-50f4-46e5-82fc-a8f7d4cdaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимую библиотеку\n",
    "import pickle\n",
    "\n",
    "# осуществляем запись в файл\n",
    "f=open('data.pickle','wb')\n",
    "pickle.dump({'data':data,'labels':labels},f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b859de0-4a51-41cc-bc39-77bbbf717f33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884e0563-6abd-4ed2-ae15-6d4ffd215e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка обучающего набора данных\n",
    "data_dict=pickle.load(open('./data.pickle1','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46385780-68e3-4e45-b0dd-90c4caceed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем классы и функций из библиотеки scikit-learn \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2cca06e-28b4-491c-972b-40772a348e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# импортируем необходимую библиотеку\n",
    "import numpy as np\n",
    "\n",
    "# преобразуем данные в массивы numpy\n",
    "data=np.asarray(data_dict['data'])\n",
    "labels=np.asarray(data_dict['labels'])\n",
    "\n",
    "# разделяем данные на обучающую и тестовую выборки\n",
    "x_train,x_test,y_train,y_test=train_test_split(data,labels,\n",
    "                test_size=0.2,shuffle=True,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1975c0ab-eff5-4f02-81fb-53edc63934a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6012759170654% образцов было классифицированы корректно!\n"
     ]
    }
   ],
   "source": [
    "# создаем экземпляр классификатора\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "# обучаем модель\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# применяем модель к тестовым данным\n",
    "y_predict= model.predict(x_test)\n",
    "\n",
    "# рассчитываем точность классификации\n",
    "score = accuracy_score(y_predict,y_test)\n",
    "print('{}% образцов было классифицированы корректно!'.format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1eb814-1198-4eb0-96cb-233a7fc07707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# осуществляем запись в файл\n",
    "f=open('model.p','wb')\n",
    "pickle.dump({'model':model},f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bda9e6-16a7-47bb-b189-b04a3d6e5163",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5. Тестирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd71b47-609c-4928-98bd-009862955257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# cоздаем объект-экземпляр модели\n",
    "# для обнаружения и отслеживания рук\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    max_num_hands=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9cba31c-898e-4602-b6d8-0ad38c340c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка обученной модели\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# создаем объект VideoCapture для получения видеопотока\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# создаем алфавит соответсвующий меткам\n",
    "labels_dict = labels_dict = {0:'А', 1:'Б', 2:'В',\n",
    "3:'Г', 4:'Д', 5:'Е', 6:'Ж', 7:'З', 8:'И', 9:'Й',\n",
    "10:'К', 11:'Л', 12:'М', 13:'Н', 14:'О', 15:'П', \n",
    "16:'Р', 17:'С', 18:'Т', 19:'У', 20:'Ф', 21:'Х',\n",
    "22:'Ц', 23:'Ч', 24:'Ш', 25:'Щ', 26:'Ь', 27:'Ъ',\n",
    "28:'Ы', 29:'Э', 30:'Ю', 31:'Я'}\n",
    "\n",
    "# обрабатываем кадры видеопотока\n",
    "while True:\n",
    "    data_aux = []\n",
    "    x_, y_ = [], []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    H, W, _ = frame.shape\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # если обнаружены ориентиры рук на изображении\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # перебираем каждый ориентир руки на изображении\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                # вычисляем координаты ориентира\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "                data_aux.append(x)\n",
    "                data_aux.append(y)\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "        \n",
    "        # вычисляем границы рамки\n",
    "        x1 = int(min(x_) * W) - 20\n",
    "        y1 = int(min(y_) * H) - 20\n",
    "\n",
    "        x2 = int(max(x_) * W) + 90\n",
    "        y2 = int(max(y_) * H) + 10\n",
    "        \n",
    "        # получаем резултат распознавания\n",
    "        prediction = model.predict([data_aux])\n",
    "        predicted_letter = labels_dict[int(prediction[0])]\n",
    "        \n",
    "        # отображаем результат\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 3)\n",
    "        cv2.putText(frame, predicted_letter, (x1, y1 - 10),\n",
    "        cv2.FONT_HERSHEY_COMPLEX, 1.3, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    # выход из программы\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "# освобождаем поток объекта VideoCapture и закрываем все окна \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec6c84-70ce-41c4-a2c3-b2d87c0a597b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6. Продвинутая версия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c0844f-a68b-4f2c-8ed8-1ad463347d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# cоздаем объект-экземпляр модели\n",
    "# для обнаружения и отслеживания рук\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    max_num_hands=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc2537d-1639-47b5-9b37-64f9455f84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка обученной модели\n",
    "import time\n",
    "\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "# создаем объект VideoCapture для получения видеопотока\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# создаем алфавит соответсвующий меткам\n",
    "labels_dict = labels_dict = {0:'А', 1:'Б', 2:'В',\n",
    "3:'Г', 4:'Д', 5:'Е', 6:'Ж', 7:'З', 8:'И', 9:'Й',\n",
    "10:'К', 11:'Л', 12:'М', 13:'Н', 14:'О', 15:'П', \n",
    "16:'Р', 17:'С', 18:'Т', 19:'У', 20:'Ф', 21:'Х',\n",
    "22:'Ц', 23:'Ч', 24:'Ш', 25:'Щ', 26:'Ь', 27:'Ъ',\n",
    "28:'Ы', 29:'Э', 30:'Ю', 31:'Я'}\n",
    "\n",
    "current_letter = ''\n",
    "last_prediction_time = 0\n",
    "last_letter_time = 0\n",
    "sentence = ''\n",
    "\n",
    "# обрабатываем кадры видеопотока\n",
    "while True:\n",
    "    data_aux = []\n",
    "    x_, y_ = [], []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    H, W, _ = frame.shape\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "         # если обнаружены ориентиры рук на изображении\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # перебираем каждый ориентир руки на изображении\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for i in range(len(hand_landmarks.landmark)):\n",
    "                # вычисляем координаты ориентира\n",
    "                x = hand_landmarks.landmark[i].x\n",
    "                y = hand_landmarks.landmark[i].y\n",
    "                data_aux.append(x)\n",
    "                data_aux.append(y)\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "                \n",
    "        # вычисляем границы рамки\n",
    "        x1 = int(min(x_) * W) - 20\n",
    "        y1 = int(min(y_) * H) - 20\n",
    "\n",
    "        x2 = int(max(x_) * W) +90\n",
    "        y2 = int(max(y_) * H) +10\n",
    "        \n",
    "        # набор текста с помощью жестов\n",
    "        current_time = time.time()\n",
    "        if current_time - last_prediction_time >= 1:\n",
    "            prediction = model.predict([data_aux])\n",
    "            predicted_letter = labels_dict[int(prediction[0])]\n",
    "            if predicted_letter == current_letter:\n",
    "                if current_time - last_letter_time >= 1:\n",
    "                    sentence += current_letter\n",
    "                    last_letter_time = current_time\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 165, 255), -1)\n",
    "            else:\n",
    "                current_letter = predicted_letter\n",
    "                last_letter_time = current_time\n",
    "                last_prediction_time = current_time\n",
    "       \n",
    "                \n",
    "        # отображаем результат\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 3)\n",
    "        cv2.putText(frame, current_letter, (x1, y1 - 10), cv2.FONT_HERSHEY_COMPLEX, 1.3, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, sentence, (20, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # выход из программы\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "# освобождаем поток объекта VideoCapture и закрываем все окна \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
